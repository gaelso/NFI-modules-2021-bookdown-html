[["index.html", "Interactive training modules on National Forest Inventory data analysis Cover page", " Interactive training modules on National Forest Inventory data analysis Handbook with solutions October 2021 Cover page DRAFT         Interactive training modules on National Forest Inventory data analysis: Handbook with solutions   ADD Authors FAO, Goettingen   ADD Recommended citation Authors, Interactive training modules on National Forest Inventory data analysis - handbook with solutions, Food and Agricultural Organization of the United Nations, Rome.   ADD Disclaimer   ADD license Recommend: CC NC SA 4 for the book, MIT for the code, Underlying data © FAO, 2021.   ADD Photo credit Example: Lauri Vesa (cover photo, photo 4.1) "],["foreword.html", "Foreword Versions notes", " Foreword DRAFT Welcome to the interactive training module on NFI data analysis with R. This interactive module has been developed with the R programming and statistical language and Rstudio IDE. It has been made possible with a great number of additioncal packages developed by the R ommunity, most importantly knitr, rmarkdown, bookdown, shiny and learnr. They are amazing packages for integrating R code and formatted text together in documents and webpages that you will hopefully find good looking and functional! The data analysis itself can be carried out with a number of applications, but R has been chosen because its free, opensource, has a large and active community of users that can help each others. It has solutions for all the steps required to take data from a forest inventory field campaign and derive statistics. If you dont have any experience of programming languages, we strongly recommend you to go through a general basic introduction to R before you complete this module. The formulas and concepts presented here were taken from the NFI training modules [LINK] and can be applied outside of the exercises in this interactive module. For an introduction to R. there are plenty of resources freely available on the internet but if you dont know where to start, and since a good amount of our code is based on the tidyverse collection of R packages, you could try R for Data Science. The book introduction will guide you through installing R, R studio, key packages and the main functions that you will find here for data wrangling. Versions notes V1.0 One country based on a 90 km square with a 30 m resolution topogr4phy and land cover map. Five forest types including mangrove forest. Random and systematic sampling design. Fixed 20 circular plot designs Calculation chain for the average forest aboveground carbon stock Stay tuned for V2.0. New features planned: Choose between several land profiles. Customize the number of forest categories and climatic conditions. Practice stratified sampling design. Practice different plot and cluster-plot designs. Estimate additional indicators such as biodiversity. "],["introduction.html", "Introduction Context An interactive module to practice sampling and carbon stock calculations", " Introduction DRAFT Context Data analysis is a larger concept than National Forest Inventory estimation design. It is not limited to the calculation of variables of interest from field measurements. There are numerous deifnitons for data analysis, one of the earliest being: Procedures for analyzing data, techniques for interpreting the results of such procedures, ways of planning the gathering of data to make its analysis easier, more precise or more accurate, and all the machinery and results of (mathematical) statistics which apply to analyzing data (John Tukey, The Future of Data Analysis, 1961). Different fields touching on data analysis have different steps to encompass the workflow for analyzing data, but they can more or less be divided into: Data requirements, Data collection, Data processing, Data cleaning, Exploratory data analysis, Modelling and algorithms, Data product, Communication. In the context of the NFI modules [LINK], we have already seen most of these steps under different names. Data requirements include NFI sampling and plot designs (NFI Module 3), together with the strategy and objectives of the NFI (NFI Modules 1 and 2). Data collection is the field work part of NFI (NFI Module 4). Data processing is adressed in the data management (NFI Module 5). Data cleaning is maybe the most important part of the data analysis workflow. Several data cleaning tips are provided in QAQC (NFI module 6), although this module is also related to field work and data management. The data cleaning, exploratory data analysis, modeling and data products are at the heart of this interactive training module and are encompassed under the data analysis part of the NFI workflow, keeping in mind that some of these elements are touched upon in the NFI modules 1-6. The interactive module also starts with a short practice on NFI design, to help you have a good overall picture on how to start exploring with sampling. An interactive module to practice sampling and carbon stock calculations This interactive module is designed to complement the NFI training modules [LINK] with practical hands-on exercises on a fictional island that just emerged in the middle of the Atlantic [Pacific?] Ocean. Although this land is not an official country, we will use the acronym NFI when referring to its forest inventory as the method and formulas applied here are valid for nationwide forest inventories. To limit the scope of this training: This NFI main objective is to estimate the overall average aboveground forest carbon stock (tCO2/ha) of the island. You wont go to the field! The plot and trees measurements are generated randomly from a large database of anonymized forest measurements [Credits or keep it completely anonymous?] What you will do is: Estimate the number of plots necessary to have the desired precision on the target estimator, Create a sampling a plot design [Plot design optimization in V2.0], Read and clean the field data, Add ancillary data (wood density, climatic factors, allometric equations) from external sources, Propagate tree biomass to plot, forest type and nationwide average with confidence interval. Lets get started! "],["newland.html", "1 A new land has emerged 1.1 First view 1.2 Preliminary information", " 1 A new land has emerged DRAFT 1.1 First view An island previously unknown to humankind has just been discovered and you are part of a team of scientists commissioned to inventory its forest resources, mainly its carbon stock. Before we start, how would you name the newly found land? You have chosen: Louland. In a future version of this interactive training module, you will be able to choose different land profiles with different (1) forest categories, (2) ratio of ocean covering the 90 km square frame in which the new land is created, (3) inclusion or not of mangrove forests and even (4) the maximum altitude of Louland (it will have an impact on unaccessible plots)! For now, Louland forests are divided into 4 categories plus Mangrove Forests and all the island is considered accessible. Great! Here is Louland looks like. Your browser does not support the video tag. The remote sensing team has developed land cover and topographic maps based on 30 m resolution remote sensing images and a first exploration crew measured a few forest plots. Based on their observations, we will be able to have a quick overview of Louland. This data is call auxiliary data, it is not NFI data per se, but useful information to help designing and implementating an NFI. 1.2 Preliminary information 1.2.1 Results of a small scale forest inventory First, lets have a look at the results of 10 forest plots measured by the exploration crew. The data is stored in the object fi_agb, by running the object name in the console we will see the results: fi_agb # A tibble: 1 x 8 n_plot n_tree mean_ba sd_ba mean_agb sd_agb ci ci_perc &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 10 658 34.6 20.6 295. 184. 114. 39 ADD variable description   the 10 plots come from a random sample in one of the Evergreen Forest of Louland. The crew also share the plot level aboveground biomass in the table fi_pagb. Run the table fi_pagb in the console below to see the table basic information: ## Empty console fi_pagb # A tibble: 10 x 4 plot_id count_tree plot_ba plot_agb &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 ev-be1o 790 20.7 166. 2 ev-fh4s 1179 51.9 493. 3 ev-leu9 469 71.1 546. 4 ev-nv7h 1075 46.6 421. 5 ev-ppw7 1631 45.0 292. 6 ev-qc3d 24 2.05 13.0 7 ev-rm6y 463 19.0 98.5 8 ev-sl7s 280 43.1 482. 9 ev-tdk3 248 29.7 277. 10 ev-unx8 421 16.4 168.   Given that the crew chose the plot location randomly, we can use simple aggregating functions to re-calculate the forest mean aboveground biomass and confirm their calculation. We will use a mix of base R tidyverse functions, in particular summarise(). This functions is very handy to aggregate numerical variables in different columns of our plot table and can even be used in combination to group_by() to summarize based on category variables (more on that later, with the full NNFI data). Lets see for example how to calculate the mean basal area of the forest and its standard deviation, and save the results in a table exfi_ba. After you create the table, run the table name in the console to display its content. exfi_ba &lt;- fi_pagb %&gt;% summarise( mean_ba = mean(plot_ba), sd_ba = sd(plot_ba) ) exfi_ba # A tibble: 1 x 2 mean_ba sd_ba &lt;dbl&gt; &lt;dbl&gt; 1 34.6 20.6   Now its your turn, create a table exfi_agb with the columns mean_agb and sd_agb and display the results. ## Guided exfi_agb &lt;- fi_pagb %&gt;% summarise( mean_agb = mean(plot_agb), sd_agb = sd(plot_agb) ) exfi_agb # A tibble: 1 x 2 mean_agb sd_agb &lt;dbl&gt; &lt;dbl&gt; 1 295. 184. 1.2.2 land cover and areas Second, we can use the land cover shapefile provided to us to view the different land covers and calculate the area of the forest. The shapefile is loaded in the environment with the name sf_newland with the package sf. It contains both the attribute table, the geometries and the coordinate reference system. Running the object name in the console displays summary information: sf_newland Simple feature collection with 515 features and 6 fields Geometry type: GEOMETRY Dimension: XY Bounding box: xmin: 560363 ymin: 9919901 xmax: 650363 ymax: 10009900 Projected CRS: WGS 84 / UTM zone 27S First 10 features: lc id id_lc w hex geometry lc_f 1 NF 1 1 0.37 #edf5e1 POLYGON ((612499.4 10009875... NF 2 EV 2 5 0.11 #00743f POLYGON ((568874 10009825, ... EV 3 PL 3 2 0.21 #8ee4af POLYGON ((570667.8 10009837... PL 4 PL 4 2 0.21 #8ee4af POLYGON ((572182.9 10009838... PL 5 NF 6 1 0.37 #edf5e1 POLYGON ((619163.7 10009798... NF 6 DD 7 3 0.08 #5cdb95 POLYGON ((570477.1 10009862... DD 7 NF 8 1 0.37 #edf5e1 POLYGON ((562017 10009822, ... NF 8 EV 9 5 0.11 #00743f POLYGON ((616639.4 10009767... EV 9 EV 10 5 0.11 #00743f POLYGON ((567944.9 10009325... EV 10 EV 11 5 0.11 #00743f POLYGON ((618336.6 10007781... EV sf objects behave similarly with standard data frames, making it easy to apply tidyverse functions to them or to convert them to simple data data frames with as_tibble(). The sf package also contains the st_area() function that we are going to use to calculate the overall area of the land covers. area_lc &lt;- sf_newland %&gt;% mutate(area_ha = st_area(.) %&gt;% units::set_units(value = ha)) %&gt;% as_tibble() %&gt;% group_by(lc_f) %&gt;% summarise(area_ha = sum(area_ha)) area_lc # A tibble: 7 x 2 lc_f area_ha &lt;fct&gt; [ha] 1 WA 3849. 2 NF 158229. 3 PL 153001. 4 DD 64084. 5 MD 186330. 6 EV 88991. 7 MG 10990. ADD dynamic/static map with land cover and first FI plot AGB "],["sampling.html", "2 Create a Sampling and Plot Design 2.1 Calculate the number of random samples 2.2 Plot designs", " 2 Create a Sampling and Plot Design 2.1 Calculate the number of random samples Choose your main NFI objective and the key variable to measure In this interactive module the main variable of interest is the forest mean aboveground biomass. In this version we will limit ourselves to random and systematic samples, but with post stratification we will also get an aboveground biomass estimates for each forest type. ADD Note on next version, stratified sampling, biodiversity as main variable of interest Indicative variability for your key variable of interest Remember in the NFI module lesson 3, the formula to estimate the sampling size n is: \\[n = \\left(\\frac{CV \\cdot t^{1 - \\alpha/2}_n}{A}\\right)^2 = \\left(\\frac{CV \\cdot 1.96}{A}\\right)^2\\] with \\(CV = \\mu / \\sigma\\) the NFI main variable coefficient of variation (i.e. average \\(\\mu\\) divided by standard deviation \\(\\sigma\\)) and \\(A\\) the desired precision. Thanks to fi_agb, we have \\(\\mu\\) and \\(\\sigma\\) for ``Loulands NFI. The desired precision depends on both the precision you expect for the NFI and your budget constraints. In case of a systematic sampling we can add an additional constraint that we want the NFI grid to be a round km value. Lets first calculate the number of sample for different precision levels. For a 5% precision, the number of sample is: n05 &lt;- ((fi_agb$mean_agb / fi_agb$sd_agb) * 1.96 / 0.05)^2 n05 [1] 3967.777   Your turn, calculate n10, n15 and n20, the number of samples necessary to get respectively 10%, 15% and 20% precision on Loulands mean aboveground biomass. Calculations for 10% here: ## Guided n10 &lt;- ((fi_agb$mean_agb / fi_agb$sd_agb) * 1.96 / 0.1)^2 n10 [1] 991.9442   Calculations for 15% here: ## Guided n15 &lt;- ((fi_agb$mean_agb / fi_agb$sd_agb) * 1.96 / 0.15)^2 n15 [1] 440.8641   Calculations for 10% here: ## Empty console n20 &lt;- ((fi_agb$mean_agb / fi_agb$sd_agb) * 1.96 / 0.2)^2 n20 [1] 247.986 Multiple choices We have enough budget for around 600 plots. What is the best range of precision we can afford? 5% - 10% 10% - 15% 15% - 20%   Systematic sampling design Now lets see what grid spacing this would lead to. To get the exact number of samples (at least according to our preliminary data, some forest plot may very well be non forest on the ground), we will start from a systematic sampling design. This way we can account for the additional constraint on grid spacing, and afterwards we will make a simple random sampling that matches the same number of plots. The sf package contains the function st_make_grid() to create random and grid points within an existing polygon. Lets start with n15. The new land fits more or less in a 90 km square, meaning that if we were to place a sampling plot at the center of each square of a 1 km grid we would have 90 * 90 = 8100 sampling plots. Similarly a 4 km grid would give us approximately (90 / 4)^2 = 506.25 plots. The 4 km grid Thats a good start. Lets make the grid. We have the sf_boundary shapefile that contains the administrative boundary of Louland. Also we will offset the grid 1 km South and 1 km West of the land most southern and Western point to avoid have too many plots at the edge of the land. ## Might as well be hidden offset &lt;- st_bbox(sf_newland)[c(&quot;xmin&quot;, &quot;ymin&quot;)] + c(-1000, -1000) We make the grid with the option what = \"polygon\" sf_grid4 &lt;- st_make_grid(sf_newland, cellsize = c(4000, 4000), what = &quot;polygons&quot;, offset = offset) %&gt;% st_intersection(sf_boundary)  And the points with the option what = \"center\" (replace \"center\" with \"corner\" to have the point at the grid intersections). sf_points4 &lt;- st_make_grid(sf_newland, cellsize = c(4000, 4000), what = &quot;centers&quot;, offset = offset) %&gt;% st_intersection(sf_boundary) %&gt;% st_as_sf() We can extract the land cover information at each plot location with st_intersection() sf_plot4 &lt;- sf_points4 %&gt;% st_join(sf_newland) %&gt;% mutate(lc_f = fct_reorder(lc, id_lc)) %&gt;% filter(!is.na(lc_f))  And visualize the grid with the following code (we have a custom color palette newland_palette for Louland land covers). ggplot() + geom_sf(data = sf_newland, aes(fill = lc_f), color = NA) + geom_sf(data = sf_plot4, aes(fill = lc_f), shape = 21) + geom_sf(data = sf_grid4, fill = NA, col = &quot;red&quot;, size = 0.6) + geom_sf(data = sf_boundary, fill = NA, size = 1.2) + scale_fill_manual(values = newland_palette) + labs(fill = &quot;&quot;, color = &quot;&quot;) + theme_void()   Looking good! To calculate the number of plot in each forest type and the total we can use group_by() and summarise() again. nplot4 &lt;- sf_plot4 %&gt;% as_tibble() %&gt;% group_by(lc_f) %&gt;% summarise(n = n()) nplot4 # A tibble: 7 x 2 lc_f n &lt;fct&gt; &lt;int&gt; 1 WA 3 2 NF 102 3 PL 93 4 DD 37 5 MD 129 6 EV 54 7 MG 5 We then need to remove non-forest categories with filter() and sum the remaining number of plots. nplot4_total &lt;- nplot4 %&gt;% filter(!(lc_f %in% c(&quot;WA&quot;, &quot;NF&quot;))) %&gt;% summarise(n = sum(n)) nplot4_total # A tibble: 1 x 1 n &lt;int&gt; 1 318   While we can definitely afford this sampling size, we can try to intensify a bit to increase our precision. In our very first approximation we didnt account for the fact that a ggod proportion of the land is non-forest. You turn! Prepare sf_pointx, sf_plotx, nplotx and nplotx_total with x taking the values 3 and 2 for creating respectively a 3 and 2 km grids. The 3 km grid Create directly: Points with the option what = \"center\". ## Guided sf_points3 &lt;- st_make_grid(sf_newland, cellsize = c(3000, 3000), what = &quot;centers&quot;, offset = offset) %&gt;% st_intersection(sf_boundary) %&gt;% st_as_sf()   Plots by joining the land cover shapefile sf_newland. ## Guided sf_plot3 &lt;- sf_points3 %&gt;% st_join(sf_newland) %&gt;% mutate(lc_f = fct_reorder(lc, id_lc)) %&gt;% filter(!is.na(lc_f))   A map with the plots over the land cover (remember we have a custom color palette newland_palette for Louland land covers). ## Guided ggplot() + geom_sf(data = sf_newland, aes(fill = lc_f), color = NA) + geom_sf(data = sf_plot3, aes(fill = lc_f), shape = 21) + scale_fill_manual(values = newland_palette) + labs(fill = &quot;&quot;, color = &quot;&quot;) + theme_void()   Calculations of the number of plots per land cover class. ## Guided nplot3 &lt;- sf_plot3 %&gt;% as_tibble() %&gt;% group_by(lc_f) %&gt;% summarise(n = n()) nplot3 # A tibble: 7 x 2 lc_f n &lt;fct&gt; &lt;int&gt; 1 WA 6 2 NF 179 3 PL 164 4 DD 76 5 MD 200 6 EV 106 7 MG 5 And the total number of plot in forests. ## Guided nplot3_total &lt;- nplot3 %&gt;% filter(!(lc_f %in% c(&quot;WA&quot;, &quot;NF&quot;))) %&gt;% summarise(n = sum(n)) nplot3_total # A tibble: 1 x 1 n &lt;int&gt; 1 551 Good job! The 3 km grid looks like exactly what we need. Lets still design a 2 km grid to see if we could afford it. The 2 km grid Create directly: Points with the option what = \"center\". ## Empty console sf_points2 &lt;- st_make_grid(sf_newland, cellsize = c(2000, 2000), what = &quot;centers&quot;, offset = offset) %&gt;% st_intersection(sf_boundary) %&gt;% st_as_sf()   Plots by joining the land cover shapefile sf_newland. ## Empty console sf_plot2 &lt;- sf_points2 %&gt;% st_join(sf_newland) %&gt;% mutate(lc_f = fct_reorder(lc, id_lc)) %&gt;% filter(!is.na(lc_f))   A map with the plots over the land cover (remember we have a custom color palette newland_palette for Louland land covers). ## Empty console ggplot() + geom_sf(data = sf_newland, aes(fill = lc_f), color = NA) + geom_sf(data = sf_plot2, aes(fill = lc_f), shape = 21) + scale_fill_manual(values = newland_palette) + labs(fill = &quot;&quot;, color = &quot;&quot;) + theme_void()   Calculations of the number of plots per land cover class. ## Empty console nplot2 &lt;- sf_plot2 %&gt;% as_tibble() %&gt;% group_by(lc_f) %&gt;% summarise(n = n()) nplot2 # A tibble: 7 x 2 lc_f n &lt;fct&gt; &lt;int&gt; 1 WA 10 2 NF 390 3 PL 378 4 DD 165 5 MD 462 6 EV 215 7 MG 30 And the total number of plot in forests. ## Empty console nplot2_total &lt;- nplot2 %&gt;% filter(!(lc_f %in% c(&quot;WA&quot;, &quot;NF&quot;))) %&gt;% summarise(n = sum(n)) nplot2_total # A tibble: 1 x 1 n &lt;int&gt; 1 1250   ADD exercise: what grid to select Good job! The 2 km grid is outside our budget constraint so we will continue with the 3 km grid! Recap Based on the preliminary inventory and few R skills, we have now identified a good sampling grid. To recap the process was: We used the preliminary forest inventory results to calculate a an hypothetical number of samples required for a desired precision of 5, 10, 15 or 20%. Based on our available budget we have identified a suitable range of sampling sizes. We have then created different sampling grids to Louland and estimated how many plots would fall on forest land. We have selected the most adequate sampling grid based on our budget/precision trade-off. Now lets see what the same amount of sampling points would give us with a random sampling or with an uneven systematic sampling. 2.1.1 Random Sampling TBD 2.1.2 Uneven Systematic Sampling TBD 2.2 Plot designs In this version of the interactive module, the plot design is limited to one choice: circular plot of 20 m radius for all trees with a diameter at breast height bigger than orr equal to 20 cm, nested circular plot of 5 m radius for trees with a diameter at breast height bigger than or equal to 10 cm and smaller than 20 cm. Lets see for example all the trees measured in one plot: \"ev-ywt8\". "],["collect.html", "3 Data collection and processing 3.1 Planification 3.2 Field work results provided 3.3 Plots not accessible 3.4 Data processing", " 3 Data collection and processing 3.1 Planification 3.2 Field work results provided 3.3 Plots not accessible 3.4 Data processing "],["clean.html", "4 Data cleaning 4.1 Visualizations 4.2 Corrections", " 4 Data cleaning The first data analysis steps requiring a bit of coding is the data cleaning stage. The data cleaning is the most important and the most time consuming part of the data analysis workflow. All errors and and data entry mistakes that are not detected in this stage can lead to erroneous products or require to remove large amounts of costly field measurements a later stage if data products become nonsensical. Figure 4.1: Workshop of OF Collect (photo: Lauri Vesa). [placeholder for image on data cleaning] The data cleaning stage is recommended to start with the data collection and continuously run during the data collection phase. The cleaning process can then feedback potential entry errors to field crews while they are still near the measured plots. Field crews could then remeasure or correct errors and avoid data loss. 4.1 Visualizations 4.2 Corrections 4.2.1 Diameter and height 4.2.2 Tree location 4.2.3 Species list "],["cstock.html", "5 Calculating the new lands forest carbon stock 5.1 Ancillary data 5.2 Allometric equations 5.3 Tree carbon 5.4 Plot carbon 5.5 Forest level", " 5 Calculating the new lands forest carbon stock 5.1 Ancillary data 5.2 Allometric equations 5.3 Tree carbon 5.4 Plot carbon 5.5 Forest level "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
